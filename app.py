import urllib.parse
import requests
import gradio as gr
from transformers import pipeline, MBart50Tokenizer

# ğŸŸ¢ API Templates Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§
SEARCH_TEMPLATE = "https://ar.wikipedia.org/w/api.php?action=opensearch&search=%s&limit=1&namespace=0&format=json"
CONTENT_TEMPLATE = "https://ar.wikipedia.org/w/api.php?format=json&action=query&prop=extracts&exintro&explaintext&redirects=1&titles=%s"

# ğŸ”¥ Ø§Ø³ØªØ®Ø¯Ø§Ù… tokenizer Ø§Ù„ØµØ­ÙŠØ­
tokenizer = MBart50Tokenizer.from_pretrained("facebook/mbart-large-50", use_fast=False)
summarizer = pipeline("summarization", model="facebook/mbart-large-50", tokenizer=tokenizer)

def search_wikipedia(query):
    """ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ù…Ù„Ø®Øµ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„. """
    query_encoded = urllib.parse.quote_plus(query)
    search_response = requests.get(SEARCH_TEMPLATE % query_encoded).json()

    if not search_response or not search_response[1]:  
        return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬.", ""

    # ğŸŸ¢ Ø¬Ù„Ø¨ Ø£ÙˆÙ„ Ù†ØªÙŠØ¬Ø©
    page_title = search_response[1][0]
    page_encoded = urllib.parse.quote_plus(page_title)
    
    # ğŸŸ¢ Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„Ø©
    content_response = requests.get(CONTENT_TEMPLATE % page_encoded).json()
    pages = content_response.get("query", {}).get("pages", {})
    
    if not pages:
        return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.", ""

    content = list(pages.values())[0].get("extract", "")

    if not content:
        return "âŒ Ø§Ù„Ù…Ù‚Ø§Ù„Ø© Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©.", ""

    # ğŸŸ¢ Ø¶Ø¨Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    max_input_length = 1024
    content = content[:max_input_length]

    # ğŸŸ¢ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„Ø©
    max_length = 200 if len(content) > 1000 else 100
    min_length = 50 if len(content) > 500 else 30

    summary = summarizer(content, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']

    source = search_response[3][0]  # Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ
    return summary, source

def chatbot_response(message, history):
    """ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… """
    summary, source = search_wikipedia(message)
    response = f"ğŸ”¹ **Ù…Ù„Ø®Øµ ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§:**\n\n{summary}"
    if source:
        response += f"\n\nğŸ”— **Ø§Ù„Ù…ØµØ¯Ø±:** [Ø§Ø¶ØºØ· Ù‡Ù†Ø§]({source})"
    history.append((message, response))
    return history

# ğŸ”¥ ÙˆØ§Ø¬Ù‡Ø© Gradio Ø§Ù„Ù…Ø­Ø³Ù†Ø©
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ¤– Ø¨ÙˆØª ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    gr.Markdown("ğŸ”¹ Ù‡Ø°Ø§ Ø§Ù„Ø¨ÙˆØª ÙŠØ³ØªØ®Ø¯Ù… ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ¥Ø¹Ø·Ø§Ø¡ Ù…Ù„Ø®Øµ Ø¹Ù†Ù‡Ø§.")

    chatbot = gr.Chatbot()
    msg = gr.Textbox(label="ğŸ” Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§:")
    clear = gr.Button("ğŸ§© Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

    msg.submit(chatbot_response, [msg, chatbot], chatbot).then(
        lambda _: "", None, [msg], queue=False  # ğŸŸ¢ ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø­Ù‚Ù„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
    )
    clear.click(lambda: [], None, chatbot, queue=False)

if __name__ == "__main__":
    demo.launch(share=True)  # ğŸŸ¢ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø¹Ø§Ù…Ø©
